{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ee0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from network.studentNet import CNN_RIS\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class GradCam:\n",
    "    def __init__(self, model):\n",
    "        self.model = model.eval()\n",
    "        self.feature = None\n",
    "        self.gradient = None\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradient = grad\n",
    "\n",
    "    def __call__(self, x):\n",
    "        image_size = (x.size(-1), x.size(-2))\n",
    "        datas = Variable(x)\n",
    "        heat_maps = []\n",
    "        for i in range(datas.size(0)):\n",
    "            img = datas[i].data.cpu().numpy()\n",
    "            img = img - np.min(img)\n",
    "            if np.max(img) != 0:\n",
    "                img = img / np.max(img)\n",
    "\n",
    "            feature = datas[i].unsqueeze(0)\n",
    "            for name, module in self.model.named_children():\n",
    "                feature = module(feature)\n",
    "                if name == 'dense3':\n",
    "                    feature.register_hook(self.save_gradient)\n",
    "                    self.feature = feature\n",
    "                    break\n",
    "            classes = F.sigmoid(feature)\n",
    "            classes = F.avg_pool2d(classes, kernel_size=5).view(classes.size(0), -1)\n",
    "            one_hot, _ = classes.max(dim=-1)\n",
    "            self.model.zero_grad()\n",
    "            one_hot.backward()\n",
    "\n",
    "            weight = self.gradient.mean(dim=-1, keepdim=True).mean(dim=-2, keepdim=True)\n",
    "            mask = F.relu((weight * self.feature).sum(dim=1)).squeeze(0)\n",
    "            mask = cv2.resize(mask.data.cpu().numpy(), image_size)\n",
    "            mask = mask - np.min(mask)\n",
    "            if np.max(mask) != 0:\n",
    "                mask = mask / np.max(mask)\n",
    "            heat_map = np.float32(cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET))\n",
    "            cam = heat_map + np.float32((np.uint8(img.transpose((1, 2, 0)) * 255)))\n",
    "            cam = cam - np.min(cam)\n",
    "            if np.max(cam) != 0:\n",
    "                cam = cam / np.max(cam)\n",
    "            heat_maps.append(transforms.ToTensor()(cv2.cvtColor(np.uint8(255 * cam), cv2.COLOR_BGR2RGB)))\n",
    "        heat_maps = torch.stack(heat_maps)\n",
    "        return heat_maps\n",
    "\n",
    "def load_pretrained_model(model, pretrained_dict):\n",
    "\tmodel_dict = model.state_dict()\n",
    "\t# 1. filter out unnecessary keys\n",
    "\tpretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "\t# 2. overwrite entries in the existing state dict\n",
    "\tmodel_dict.update(pretrained_dict) \n",
    "\t# 3. load the new state dict\n",
    "\tmodel.load_state_dict(model_dict)\n",
    "    \n",
    "NUM_CLASSES = 7\n",
    "snet = CNN_RIS(num_classes=NUM_CLASSES).cuda()\n",
    "files = os.listdir('picture/')\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc64393",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheckpoint = torch.load('results/RAF_MultiTeacher_OurDiversity_0.0_0.0_KD3/Student_Test_model.t7')\n",
    "load_pretrained_model(snet, scheckpoint['snet'])\n",
    "\n",
    "for filename in files:\n",
    "    IMAGE_NAME = os.path.join('picture/',filename)\n",
    "    \n",
    "    pil_img = Image.open(IMAGE_NAME)\n",
    "    torch_img = transforms.Compose([\n",
    "        transforms.Resize((44, 44)),\n",
    "        transforms.ToTensor()\n",
    "    ])(pil_img).to(device)\n",
    "    test_image = transforms.Normalize([0.59003043, 0.4573948, 0.40749523], [0.2465465, 0.22635746, 0.22564183])(torch_img)[None]\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        test_image = test_image.cuda()\n",
    "        snet.cuda()\n",
    "    grad_cam = GradCam(snet)\n",
    "    feature_image = grad_cam(test_image).squeeze(dim=0)\n",
    "    feature_image = transforms.ToPILImage()(feature_image)\n",
    "    rb1_s, rb2_s, rb3_s, mimic_s, out_s = snet(test_image)\n",
    "    feature_image.save(os.path.join(IMAGE_NAME.split('.')[0]+'_0000.jpg'), quality = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57083c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheckpoint = torch.load('results/RAF_MultiTeacher_Few-Shot_KD3/Student_Test_model.t7')\n",
    "load_pretrained_model(snet, scheckpoint['snet'])\n",
    "\n",
    "for filename in files:\n",
    "    IMAGE_NAME = os.path.join('picture/',filename)\n",
    "    \n",
    "    pil_img = Image.open(IMAGE_NAME)\n",
    "    torch_img = transforms.Compose([\n",
    "        transforms.Resize((44, 44)),\n",
    "        transforms.ToTensor()\n",
    "    ])(pil_img).to(device)\n",
    "    test_image = transforms.Normalize([0.59003043, 0.4573948, 0.40749523], [0.2465465, 0.22635746, 0.22564183])(torch_img)[None]\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        test_image = test_image.cuda()\n",
    "        snet.cuda()\n",
    "    grad_cam = GradCam(snet)\n",
    "    feature_image = grad_cam(test_image).squeeze(dim=0)\n",
    "    feature_image = transforms.ToPILImage()(feature_image)\n",
    "    rb1_s, rb2_s, rb3_s, mimic_s, out_s = snet(test_image)\n",
    "    feature_image.save(os.path.join(IMAGE_NAME.split('.')[0]+'_FewShot.jpg'), quality = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27df35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheckpoint = torch.load('results/RAF_MultiTeacher_OurDiversity_0.8_9.0_KD3/Student_Test_model.t7')\n",
    "load_pretrained_model(snet, scheckpoint['snet'])\n",
    "\n",
    "for filename in files:\n",
    "    IMAGE_NAME = os.path.join('picture/',filename)\n",
    "    \n",
    "    pil_img = Image.open(IMAGE_NAME)\n",
    "    torch_img = transforms.Compose([\n",
    "        transforms.Resize((44, 44)),\n",
    "        transforms.ToTensor()\n",
    "    ])(pil_img).to(device)\n",
    "    test_image = transforms.Normalize([0.59003043, 0.4573948, 0.40749523], [0.2465465, 0.22635746, 0.22564183])(torch_img)[None]\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        test_image = test_image.cuda()\n",
    "        snet.cuda()\n",
    "    grad_cam = GradCam(snet)\n",
    "    feature_image = grad_cam(test_image).squeeze(dim=0)\n",
    "    feature_image = transforms.ToPILImage()(feature_image)\n",
    "    rb1_s, rb2_s, rb3_s, mimic_s, out_s = snet(test_image)\n",
    "    feature_image.save(os.path.join(IMAGE_NAME.split('.')[0]+'_0890.jpg'), quality = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581cffed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ysz",
   "language": "python",
   "name": "ysz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
